"""
Test text processing functionality
"""
import sys
from pathlib import Path
from unittest.mock import patch, mock_open

import pytest

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from text_processor import (  # noqa: E402
    TextProcessor,
    TextProcessingError,
    EncodingError,
    FileFormatError
)


class TestManuscriptProcessing:
    """Test manuscript file processing"""
    
    @pytest.fixture
    def text_processor(self):
        """Create TextProcessor instance"""
        return TextProcessor()
    
    def test_read_txt_file(self, text_processor):
        """TXTãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        mock_content = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã®åŸç¨¿ã§ã™ã€‚\nãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã®å†…å®¹ã«ã¤ã„ã¦è©±ã—ã¦ã„ã¾ã™ã€‚"
        
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open(read_data=mock_content)):
                result = text_processor.read_manuscript('test.txt')
            
        assert result == mock_content
        assert isinstance(result, str)
    
    def test_encoding_handling(self, text_processor):
        """UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # UTF-8 with BOM - test with string (mock_open handles it as string)
        mock_content_with_bom = "\ufeffãƒ†ã‚¹ãƒˆåŸç¨¿"
        
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open(read_data=mock_content_with_bom)):
                result = text_processor.read_manuscript('test.txt')
                assert result == "ãƒ†ã‚¹ãƒˆåŸç¨¿"
        
        # Test invalid encoding - mock a UnicodeDecodeError
        with patch('os.path.exists', return_value=True):
            mock_file = mock_open()
            mock_file.side_effect = UnicodeDecodeError('utf-8', b'', 0, 1, 'invalid start byte')
            with patch('builtins.open', mock_file):
                with pytest.raises(EncodingError) as exc_info:
                    text_processor.read_manuscript('test.txt')
                assert "Encoding error" in str(exc_info.value)
    
    def test_manuscript_priority(self, text_processor):
        """åŸç¨¿ãŒã‚ã‚‹å ´åˆã€éŸ³å£°å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # This method returns True if manuscript should be used instead of audio
        mock_content = "åŸç¨¿å†…å®¹"
        
        with patch('builtins.open', mock_open(read_data=mock_content)):
            with patch('os.path.exists', return_value=True):
                has_manuscript = text_processor.check_manuscript_exists('test.txt')
                assert has_manuscript is True
        
        # No manuscript file
        with patch('os.path.exists', return_value=False):
            has_manuscript = text_processor.check_manuscript_exists('test.txt')
            assert has_manuscript is False
    
    def test_invalid_file_format(self, text_processor):
        """éå¯¾å¿œå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ‹’å¦ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        invalid_files = ['test.pdf', 'test.doc', 'test.docx', 'test.rtf']
        
        for file_path in invalid_files:
            with pytest.raises(FileFormatError) as exc_info:
                text_processor.read_manuscript(file_path)
            assert "Unsupported file format" in str(exc_info.value)
    
    def test_file_not_found(self, text_processor):
        """å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        with patch('os.path.exists', return_value=False):
            with pytest.raises(FileNotFoundError) as exc_info:
                text_processor.read_manuscript('non_existent.txt')
            assert "File not found" in str(exc_info.value)
    
    def test_empty_file(self, text_processor):
        """ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open(read_data="")):
                result = text_processor.read_manuscript('empty.txt')
                assert result == ""
    
    def test_large_file_handling(self, text_processor):
        """å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        # 10MB of text (should be handled)
        large_content = "ã‚" * (10 * 1024 * 1024)
        
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open(read_data=large_content)):
                result = text_processor.read_manuscript('large.txt')
                assert len(result) == len(large_content)
    
    def test_read_permission_error(self, text_processor):
        """èª­ã¿å–ã‚Šæ¨©é™ãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', side_effect=PermissionError("Permission denied")):
                with pytest.raises(TextProcessingError) as exc_info:
                    text_processor.read_manuscript('protected.txt')
                assert "Permission denied" in str(exc_info.value)


class TestTextPreprocessing:
    """Test text preprocessing functionality"""
    
    @pytest.fixture
    def text_processor(self):
        """Create TextProcessor instance"""
        return TextProcessor()
    
    def test_text_cleaning(self, text_processor):
        """ãƒ†ã‚­ã‚¹ãƒˆãŒé©åˆ‡ã«ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # Test cases for cleaning
        test_cases = [
            # (input, expected)
            ("  ãƒ†ã‚¹ãƒˆ  ", "ãƒ†ã‚¹ãƒˆ"),  # Leading/trailing spaces
            ("ãƒ†ã‚¹ãƒˆ\n\n\næ–‡ç« ", "ãƒ†ã‚¹ãƒˆ\n\næ–‡ç« "),  # Multiple newlines to double
            ("ãƒ†ã‚¹ãƒˆ\r\næ–‡ç« ", "ãƒ†ã‚¹ãƒˆ\næ–‡ç« "),  # Windows line endings
            ("ãƒ†ã‚¹ãƒˆ\tæ–‡ç« ", "ãƒ†ã‚¹ãƒˆ æ–‡ç« "),  # Tab to space
            ("ãƒ†ã‚¹ãƒˆã€€ã€€æ–‡ç« ", "ãƒ†ã‚¹ãƒˆ æ–‡ç« "),  # Full-width spaces
            ("", ""),  # Empty string
        ]
        
        for input_text, expected in test_cases:
            result = text_processor.clean_text(input_text)
            assert result == expected
    
    def test_character_count(self, text_processor):
        """æ–‡å­—æ•°ãŒæ­£ã—ãã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        test_cases = [
            ("Hello", 5),
            ("ã“ã‚“ã«ã¡ã¯", 5),
            ("Hello World", 11),
            ("ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œ", 8),
            ("", 0),
            ("  ", 2),  # Spaces count
            ("ğŸ˜€ğŸ˜ƒ", 2),  # Emoji count
            ("ãƒ†ã‚¹ãƒˆ\næ”¹è¡Œ", 6),  # Newline counts as 1
        ]
        
        for text, expected_count in test_cases:
            count = text_processor.count_characters(text)
            assert count == expected_count
    
    def test_text_preprocessing_pipeline(self, text_processor):
        """å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®å‹•ä½œç¢ºèª"""
        raw_text = "  ã“ã‚Œã¯\n\n\nãƒ†ã‚¹ãƒˆã®\r\nåŸç¨¿ã§ã™ã€‚ã€€ã€€ãŸãã•ã‚“ã®ã€€ç©ºç™½ãŒã‚ã‚Šã¾ã™ã€‚  "
        
        result = text_processor.preprocess_text(raw_text)
        
        assert result['cleaned_text'] == "ã“ã‚Œã¯\n\nãƒ†ã‚¹ãƒˆã®\nåŸç¨¿ã§ã™ã€‚ ãŸãã•ã‚“ã® ç©ºç™½ãŒã‚ã‚Šã¾ã™ã€‚"
        assert result['character_count'] == 30  # Actual count after cleaning
        assert 'original_character_count' in result
        assert result['original_character_count'] == len(raw_text)
    
    def test_remove_urls(self, text_processor):
        """URLã®é™¤å»ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        test_cases = [
            ("è©³ç´°ã¯https://example.comã‚’ã”è¦§ãã ã•ã„", "è©³ç´°ã¯[URL]ã‚’ã”è¦§ãã ã•ã„"),
            ("http://test.comã¨https://test.jp", "[URL]ã¨[URL]"),
            ("URLãªã—ã®ãƒ†ã‚­ã‚¹ãƒˆ", "URLãªã—ã®ãƒ†ã‚­ã‚¹ãƒˆ"),
        ]
        
        for input_text, expected in test_cases:
            result = text_processor.remove_urls(input_text)
            assert result == expected
    
    def test_normalize_whitespace(self, text_processor):
        """ç©ºç™½ã®æ­£è¦åŒ–ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        test_cases = [
            ("ãƒ†ã‚¹ãƒˆ   æ–‡ç« ", "ãƒ†ã‚¹ãƒˆ æ–‡ç« "),  # Multiple spaces
            ("ãƒ†ã‚¹ãƒˆ\u3000\u3000æ–‡ç« ", "ãƒ†ã‚¹ãƒˆ æ–‡ç« "),  # Full-width spaces
            ("ãƒ†ã‚¹ãƒˆ\t\tæ–‡ç« ", "ãƒ†ã‚¹ãƒˆ æ–‡ç« "),  # Multiple tabs
            ("ãƒ†ã‚¹ãƒˆ\n \næ–‡ç« ", "ãƒ†ã‚¹ãƒˆ\n\næ–‡ç« "),  # Space between newlines
        ]
        
        for input_text, expected in test_cases:
            result = text_processor.normalize_whitespace(input_text)
            assert result == expected
    
    def test_text_validation(self, text_processor):
        """ãƒ†ã‚­ã‚¹ãƒˆã®æ¤œè¨¼æ©Ÿèƒ½"""
        # Valid text
        valid_text = "ã“ã‚Œã¯æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚"
        assert text_processor.validate_text(valid_text) is True
        
        # Invalid cases
        assert text_processor.validate_text("") is False  # Empty
        assert text_processor.validate_text("   ") is False  # Only spaces
        assert text_processor.validate_text("\n\n\n") is False  # Only newlines
    
    def test_extract_metadata(self, text_processor):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        text = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™ã€‚\næ®µè½ãŒè¤‡æ•°ã‚ã‚Šã¾ã™ã€‚\n\nåˆ¥ã®æ®µè½ã§ã™ã€‚"
        
        metadata = text_processor.extract_metadata(text)
        
        assert metadata['character_count'] == 29  # Corrected count
        assert metadata['line_count'] == 4  # Including empty line
        assert metadata['paragraph_count'] == 2  # Two paragraphs separated by empty line
        assert 'estimated_reading_time_seconds' in metadata
        assert metadata['estimated_reading_time_seconds'] > 0


class TestLanguageDetection:
    """Test optional language detection functionality"""
    
    @pytest.fixture
    def text_processor(self):
        """Create TextProcessor instance"""
        return TextProcessor()
    
    def test_detect_japanese(self, text_processor):
        """æ—¥æœ¬èªã®æ¤œå‡º"""
        japanese_texts = [
            "ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",
            "ã²ã‚‰ãŒãªã¨ã‚«ã‚¿ã‚«ãƒŠãŒæ··ã–ã£ã¦ã„ã¾ã™ã€‚",
            "æ¼¢å­—ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
        ]
        
        for text in japanese_texts:
            language = text_processor.detect_language(text)
            assert language == 'ja'
    
    def test_detect_english(self, text_processor):
        """è‹±èªã®æ¤œå‡º"""
        english_texts = [
            "This is English text.",
            "Hello World!",
            "Testing language detection.",
        ]
        
        for text in english_texts:
            language = text_processor.detect_language(text)
            assert language == 'en'
    
    def test_detect_mixed_language(self, text_processor):
        """æ··åˆè¨€èªã®æ¤œå‡ºï¼ˆæ—¥æœ¬èªå„ªå…ˆï¼‰"""
        # Mixed with Japanese - should return 'ja'
        text1 = "ã“ã‚Œã¯æ—¥æœ¬èªã§ã™ã€‚This is English. ã§ã‚‚ä¸»ã«æ—¥æœ¬èªã€‚"
        assert text_processor.detect_language(text1) == 'ja'
        
        # Even small Japanese content returns 'ja'
        text2 = "This is mostly English text. ã¡ã‚‡ã£ã¨æ—¥æœ¬èªã€‚ But mainly English."
        assert text_processor.detect_language(text2) == 'ja'
        
        # Pure English returns 'en'
        text3 = "This is purely English text with no Japanese characters."
        assert text_processor.detect_language(text3) == 'en'
    
    def test_detect_unknown_language(self, text_processor):
        """æœªçŸ¥ã®è¨€èªã‚„åˆ¤å®šä¸èƒ½ãªå ´åˆ"""
        # Numbers and symbols only
        assert text_processor.detect_language("123456789") == 'unknown'
        assert text_processor.detect_language("!!!???") == 'unknown'
        assert text_processor.detect_language("") == 'unknown'


class TestTextProcessorIntegration:
    """Integration tests for TextProcessor"""
    
    @pytest.fixture
    def text_processor(self):
        """Create TextProcessor instance"""
        return TextProcessor()
    
    def test_process_manuscript_file(self, text_processor):
        """åŸç¨¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼"""
        mock_content = """
        ã“ã‚Œã¯ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã®åŸç¨¿ã§ã™ã€‚
        
        ä»Šæ—¥ã®ãƒ†ãƒ¼ãƒã¯ã€ŒAIã®æ´»ç”¨ã€ã«ã¤ã„ã¦ã§ã™ã€‚
        è©³ç´°ã¯https://example.comã‚’ã”è¦§ãã ã•ã„ã€‚
        
        ãã‚Œã§ã¯ã€å§‹ã‚ã¾ã—ã‚‡ã†ã€‚
        """
        
        with patch('builtins.open', mock_open(read_data=mock_content)):
            with patch('os.path.exists', return_value=True):
                result = text_processor.process_manuscript_file('episode1.txt')
                
                assert result['status'] == 'success'
                assert 'content' in result
                assert 'metadata' in result
                assert result['metadata']['language'] == 'ja'
                assert result['metadata']['character_count'] > 0
                assert '[URL]' in result['content']  # URL should be replaced
    
    def test_process_with_encoding_options(self, text_processor):
        """ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã®å‡¦ç†"""
        # Test with UTF-8
        mock_content = "ãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open(read_data=mock_content)):
                result = text_processor.read_manuscript('test.txt', encoding='utf-8')
                assert result == mock_content
        
        # Test with UTF-8 BOM
        mock_content_bom = "\ufeffãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
        with patch('os.path.exists', return_value=True):
            with patch('builtins.open', mock_open(read_data=mock_content_bom)):
                result = text_processor.read_manuscript('test.txt', encoding='utf-8-sig')
                assert result == "ãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„"  # BOM should be removed